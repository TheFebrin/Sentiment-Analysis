{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import string \n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.optimize as sopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Macro for windows / mac users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'Mac'\n",
    "# system = 'Win'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing data (IMDb movies' reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = 'data_sets/aclImdb/train/pos/*'\n",
    "train_neg_path = 'data_sets/aclImdb/train/neg/*'\n",
    "\n",
    "train_pos = glob.glob(train_pos_path)\n",
    "train_neg = glob.glob(train_neg_path)\n",
    "\n",
    "\n",
    "test_pos_path = 'data_sets/aclImdb/test/pos/*'\n",
    "test_neg_path = 'data_sets/aclImdb/test/neg/*'\n",
    "\n",
    "test_pos = glob.glob(test_pos_path)\n",
    "test_neg = glob.glob(test_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "for path in tqdm(train_pos, desc='Getting positive train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "        \n",
    "for path in tqdm(train_neg, desc='Getting negative train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "\n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "         \n",
    "for path in tqdm(test_pos, desc='Getting positive test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])\n",
    "   \n",
    "for path in tqdm(test_neg, desc='Getting negative test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_df, columns=['text', 'rating'])\n",
    "test_df = pd.DataFrame(test_df, columns=['text', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records:  50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      9\n",
       "1  Homelessness (or Houselessness as George Carli...      8\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...     10\n",
       "3  This is easily the most underrated film inn th...      7\n",
       "4  This is not the typical Mel Brooks film. It wa...      8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Records: ', train_df.size)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with rating 1: 5100\n",
      "Number of reviews with rating 2: 2284\n",
      "Number of reviews with rating 3: 2420\n",
      "Number of reviews with rating 4: 2696\n",
      "Number of reviews with rating 5: 0\n",
      "Number of reviews with rating 6: 0\n",
      "Number of reviews with rating 7: 2496\n",
      "Number of reviews with rating 8: 3009\n",
      "Number of reviews with rating 9: 2263\n",
      "Number of reviews with rating 10: 4732\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Number of reviews with rating {i}: {train_df[train_df.rating == str(i)].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *We might consider (?or not?) only movies with reviews 1(terrible) and 10(perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove punctuaction and lower all texts\n",
    "train_df.text = train_df.text.apply(lambda row: regex(row))\n",
    "test_df.text = test_df.text.apply(lambda row: regex(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bromwell high is a cartoon comedy it ran at th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>homelessness or houselessness as george carlin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brilliant overacting by lesley ann warren best...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>this is not the typical mel brooks film it was...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  bromwell high is a cartoon comedy it ran at th...      9\n",
       "1  homelessness or houselessness as george carlin...      8\n",
       "2  brilliant overacting by lesley ann warren best...     10\n",
       "3  this is easily the most underrated film inn th...      7\n",
       "4  this is not the typical mel brooks film it was...      8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        bromwell high is a cartoon comedy it ran at th...\n",
      "1        homelessness or houselessness as george carlin...\n",
      "2        brilliant overacting by lesley ann warren best...\n",
      "3        this is easily the most underrated film inn th...\n",
      "4        this is not the typical mel brooks film it was...\n",
      "                               ...                        \n",
      "24995    towards the end of the movie i felt it was too...\n",
      "24996    this is the kind of movie that my enemies cont...\n",
      "24997    i saw descent last night at the stockholm film...\n",
      "24998    some films that you pick up for a pound turn o...\n",
      "24999    this is one of the dumbest films ive ever seen...\n",
      "Name: text, Length: 25000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only rating 1 and 10\n",
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]\n",
    "GOOD_WORDS = defaultdict(int)\n",
    "BAD_WORDS = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bayes dictionaries: 9832it [00:02, 4182.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Creating Bayes dictionaries', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    for word in text.split():\n",
    "        if rating == '10':\n",
    "            GOOD_WORDS[word] += 1\n",
    "        else:\n",
    "            BAD_WORDS[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 56972),\n",
       " ('and', 30301),\n",
       " ('a', 26016),\n",
       " ('of', 25791),\n",
       " ('to', 22249),\n",
       " ('is', 19380),\n",
       " ('in', 16257),\n",
       " ('i', 14729),\n",
       " ('it', 14595),\n",
       " ('this', 13341)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent GOOD words\n",
    "list(sorted(GOOD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 58427),\n",
       " ('a', 28386),\n",
       " ('and', 26617),\n",
       " ('to', 26292),\n",
       " ('of', 25218),\n",
       " ('is', 18370),\n",
       " ('this', 18239),\n",
       " ('i', 17985),\n",
       " ('it', 15645),\n",
       " ('in', 15538)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent BAD words\n",
    "list(sorted(BAD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, target_dict):\n",
    "    text = regex(text)\n",
    "    \n",
    "    for word in text.split():\n",
    "        if not word in target_dict:\n",
    "            target_dict[word] = 1\n",
    "            \n",
    "    sum_of_all = sum(target_dict.values())\n",
    "    \n",
    "    ppd = 0\n",
    "    for word in text.split():\n",
    "        ppd += np.log2(float(target_dict[word]) / sum_of_all)\n",
    "        \n",
    "    return ppd\n",
    "    \n",
    "    \n",
    "def predict(text):\n",
    "    ppd_good = classify(text, GOOD_WORDS)\n",
    "    ppd_bad = classify(text, BAD_WORDS)\n",
    "    \n",
    "    all_ppd = np.array([ppd_good, ppd_bad])\n",
    "    target = ['10', '1'][np.argmax(all_ppd)]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train accuracy: 9832it [00:25, 378.44it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Checking train accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9346, Wrong: 486\n",
      "Accuracy: 95.05695687550855%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4922  308]\n",
      " [ 178 4424]]\n",
      "\n",
      "True negative (rating = 1): 4922\n",
      "True positive (rating = 10): 4424\n",
      "False negative: 308\n",
      "False positive: 178\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So we are rather sceptic and most of our mistakes are movies which are good, but we classify them as bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking test accuracy: 10021it [00:33, 297.44it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_test.iterrows(), desc='Checking test accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8901, Wrong: 1120\n",
      "Accuracy: 88.82347071150583%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4689  787]\n",
      " [ 333 4212]]\n",
      "\n",
      "True negative (rating = 1): 4689\n",
      "True positive (rating = 10): 4212\n",
      "False negative: 787\n",
      "False positive: 333\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again we are sceptic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Class Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self,alpha=0,fit_prior=True,class_prior=None):\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior_array = class_prior\n",
    "        if class_prior:\n",
    "            self.fit_prior = False\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.classes,prior = np.unique(y,return_counts=True)\n",
    "        self.N = len(y)\n",
    "        \n",
    "        # Setting class prior\n",
    "        if self.fit_prior:\n",
    "            self.class_prior = {class_ : np.log(prior[i]/self.N + 1e-100) for i,class_ in enumerate(self.classes)}\n",
    "        elif self.class_prior_array:\n",
    "            self.class_prior = {class_ : np.log(self.class_prior_array[i] + 1e-100) for i,class_ in enumerate(self.classes)}\n",
    "        else:\n",
    "            self.class_prior = {class_ : np.log(1/len(self.classes) + 1e-100) for class_ in self.classes}\n",
    "            \n",
    "        # Creating words dictionaries\n",
    "        self.class_words_counts = {class_ : defaultdict(lambda: 0) for class_ in self.classes}\n",
    "        for i,text in enumerate(X):\n",
    "            target = y[i]\n",
    "            for word in text.split():\n",
    "                self.class_words_counts[target][word] += 1\n",
    "        \n",
    "        # Creating probabilities dictionaries\n",
    "        self.class_words_probs = {class_ : defaultdict(lambda: np.log(self.alpha + 1e-100)) for class_ in self.classes}\n",
    "        for class_,dict_ in self.class_words_counts.items():\n",
    "            for word,count in dict_.items():\n",
    "                self.class_words_probs[class_][word] = np.log(count + 1e-100)\n",
    "    \n",
    "        self.class_words_amount = {class_ : np.log(sum(self.class_words_counts[class_].values())) for class_ in self.classes}\n",
    "    \n",
    "\n",
    "    def get_class_log_probabilities(self,text):\n",
    "        probs = {class_ : 0 for class_ in self.classes}\n",
    "        for class_ in self.classes:\n",
    "            for word in text.split():\n",
    "                probs[class_] += self.class_words_probs[class_][word]\n",
    "                probs[class_] -= self.class_words_amount[class_]\n",
    "            probs[class_] += self.class_prior[class_]\n",
    "        return probs\n",
    "    \n",
    "    \n",
    "    def predict(self,X,return_probabilities = False):\n",
    "        preds = []\n",
    "        preds_probs = []\n",
    "        for text in X:\n",
    "            prob = self.get_class_log_probabilities(text)\n",
    "            #prob = {class_ : np.exp(pbb) for class_,pbb in prob.items()}\n",
    "            preds_probs.append(prob)\n",
    "            pred = max(prob,key = prob.get)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return preds,preds_probs\n",
    "        return preds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = np.array(bayes_df_train['text']),np.array(bayes_df_train['rating'])\n",
    "X_test,y_test = np.array(bayes_df_test['text']),np.array(bayes_df_test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 1.0\n",
      "Acc: 0.9491456468673718\n",
      "\n",
      "Confusion matrix:\n",
      "[[4963  363]\n",
      " [ 137 4369]]\n",
      "\n",
      "True negative (rating = 1): 4963\n",
      "True positive (rating = 10): 4369\n",
      "False negative: 363\n",
      "False positive: 137\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_train)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_train)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.0\n",
      "Acc: 0.8884342879952101\n",
      "\n",
      "Confusion matrix:\n",
      "[[4660  756]\n",
      " [ 362 4243]]\n",
      "\n",
      "True negative (rating = 1): 4660\n",
      "True positive (rating = 10): 4243\n",
      "False negative: 756\n",
      "False positive: 362\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEST, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_test)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_test)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 0.0\n",
      "Acc: 0.9899308380797396\n",
      "\n",
      "Confusion matrix:\n",
      "[[5092   91]\n",
      " [   8 4641]]\n",
      "\n",
      "True negative (rating = 1): 5092\n",
      "True positive (rating = 10): 4641\n",
      "False negative: 91\n",
      "False positive: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_train)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_train)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 0.0\n",
      "Acc: 0.7240794331903003\n",
      "\n",
      "Confusion matrix:\n",
      "[[3932 1675]\n",
      " [1090 3324]]\n",
      "\n",
      "True negative (rating = 1): 3932\n",
      "True positive (rating = 10): 3324\n",
      "False negative: 1675\n",
      "False positive: 1090\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEST, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_test)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_test)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha : 0.0, test acc: 0.7240794331903003\n",
      "Alpha : 0.25, test acc: 0.8820476998303562\n",
      "Alpha : 0.5, test acc: 0.8868376409539966\n",
      "Alpha : 0.75, test acc: 0.8882347071150584\n",
      "Alpha : 1.0, test acc: 0.8884342879952101\n",
      "Alpha : 1.25, test acc: 0.8881349166749826\n",
      "Alpha : 1.5, test acc: 0.8893324019558926\n",
      "Alpha : 1.75, test acc: 0.8884342879952101\n",
      "Alpha : 2.0, test acc: 0.8882347071150584\n",
      "Alpha : 3.0, test acc: 0.8872368027142999\n",
      "Alpha : 4.0, test acc: 0.8862388983135415\n",
      "Alpha : 5.0, test acc: 0.8830456042311147\n",
      "Alpha : 10.0, test acc: 0.8759604829857299\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,3.0,4.0,5.0,10.0]:\n",
    "    NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "    NB.fit(X_train,y_train)\n",
    "    predictions,ppb = NB.predict(X_test,return_probabilities=True)\n",
    "    acc = np.mean(predictions == y_test)\n",
    "    print(f'Alpha : {alpha}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can consider if stemming or removing stop words can imporove accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stemming we will use Snowball Stemming (Porter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_remove_stop_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df = bayes_df_train.copy()\n",
    "stemmed_test_df = bayes_df_test.copy()\n",
    "stemmed_train_df.text = stemmed_train_df.text.apply(lambda row: stem_(row))\n",
    "stemmed_test_df.text = stemmed_test_df.text.apply(lambda row: stem_(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "swr_train_df = bayes_df_train.copy()\n",
    "swr_test_df = bayes_df_test.copy()\n",
    "swr_train_df.text = swr_train_df.text.apply(lambda row: remove_stop_words(row))\n",
    "swr_test_df.text = swr_test_df.text.apply(lambda row: remove_stop_words(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_swr_train_df = bayes_df_train.copy()\n",
    "stemmed_swr_test_df = bayes_df_test.copy()\n",
    "stemmed_swr_train_df.text = stemmed_swr_train_df.text.apply(lambda row: stem_(row))\n",
    "stemmed_swr_test_df.text = stemmed_swr_test_df.text.apply(lambda row: stem_(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_train_df['text']),np.array(stemmed_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stemmed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(stemmed_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(stemmed_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stop words removed\n",
      "Acc: 0.8995110268436284\n",
      "\n",
      "Confusion matrix:\n",
      "[[4656  641]\n",
      " [ 366 4358]]\n",
      "\n",
      "True negative (rating = 1): 4656\n",
      "True positive (rating = 10): 4358\n",
      "False negative: 641\n",
      "False positive: 366\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(swr_train_df['text']),np.array(swr_test_df['rating']))\n",
    "predictions = NB.predict(np.array(swr_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stop words removed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(swr_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(swr_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed and stop words removed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_swr_train_df['text']),np.array(stemmed_swr_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_swr_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stemmed and stop words removed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(stemmed_swr_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(stemmed_swr_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. sklearn built in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Data vectorization (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_clean = np.array(train_df.text)\n",
    "reviews_test_clean = np.array(test_df.text)\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.86576\n",
      "Accuracy for C=0.05: 0.87856\n",
      "Accuracy for C=0.25: 0.8784\n",
      "Accuracy for C=0.5: 0.87648\n",
      "Accuracy for C=1: 0.87504\n"
     ]
    }
   ],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:    \n",
    "    lr = LogisticRegression(C=c,max_iter=300) # pobawic sie parametrami znalezc najlepsze\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "Removing stop words, stemming, encode review as a vector of words occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using reviews with rating equal 1 or 10 from training set. \n",
    "# Test samples rating will be also classified as 1 or 10\n",
    "LR_train_df = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "LR_test_df = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_train_target = np.array([int(r) for r in LR_train_df['rating']]) // 10\n",
    "LR_test_target = np.array([int(r) for r in LR_test_df['rating']]) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    words = sample.split()\n",
    "    words = [ stemmer.stem(word) for word in words if word not in stopwords_set ]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train set\n",
    "sample = '''brilliant overacting by lesley ann warren best dramatic hobo lady i \n",
    "have ever seen and love scenes in clothes warehouse are second to none the corn \n",
    "on face is a classic as good as anything in blazing saddles the take on lawyers \n",
    "is also superb after being accused of being a turncoat selling out his boss and \n",
    "being dishonest the lawyer of pepto bolt shrugs indifferently im a lawyer he says \n",
    "three funny words jeffrey tambor a favorite from the later larry sanders show is \n",
    "fantastic here too as a mad millionaire who wants to crush the ghetto his character \n",
    "is more malevolent than usual the hospital scene and the scene where the homeless \n",
    "invade a demolition site are alltime classics look for the legs scene and the two \n",
    "big diggers fighting one bleeds this movie gets better each time i see it which is \n",
    "quite often'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brilliant overact lesley ann warren best dramat hobo ladi ever seen love scene cloth warehous second none corn face classic good anyth blaze saddl take lawyer also superb accus turncoat sell boss dishonest lawyer pepto bolt shrug indiffer im lawyer say three funni word jeffrey tambor favorit later larri sander show fantast mad millionair want crush ghetto charact malevol usual hospit scene scene homeless invad demolit site alltim classic look leg scene two big digger fight one bleed movi get better time see quit often'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in LR_train_df.index:\n",
    "    sample = LR_train_df.loc[i]['text']\n",
    "    #words |= set(preprocess(sample)) <- for set of words\n",
    "    for word in preprocess(sample):\n",
    "        words[word] = words.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from all stemmed words we consider only those, which occurs more than k times\n",
    "min_occur = 3\n",
    "all_train_words = list(filter(lambda w: words[w] >= min_occur,words))\n",
    "n_w = len(all_train_words)\n",
    "n_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_words_indexes = {w:i for i,w in enumerate(all_train_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "    data = []\n",
    "    for i in df.index:\n",
    "        v = np.zeros(n_w+1, dtype=np.int32)\n",
    "        v[0] = 1\n",
    "        sample = df.loc[i]['text']\n",
    "        words = preprocess(sample)\n",
    "        for word in words:\n",
    "            idx = all_train_words_indexes.get(word,-1)\n",
    "            if idx >= 0:\n",
    "                v[idx+1] += 1\n",
    "        data.append(v)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = vectorize(LR_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 17386)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta0 = np.ones(vectorized_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_loss(Theta, X, Y):\n",
    "    print(f\"Loss calculating... \",end=\"\")\n",
    "    Z = np.dot(Theta,X.T)\n",
    "    print(f\" Z done... \",end=\"\")\n",
    "    SZ = sigmoid(Z)\n",
    "    nll = -np.sum([\n",
    "                    y * np.log2(SZ + 1e-7) \\\n",
    "                    + (1-y) * np.log2(1 - SZ + 1e-7) \\\n",
    "                    for y in Y\n",
    "                    ])\n",
    "    print(f\" nll done... \",end=\"\")\n",
    "    grad = np.dot(X.T, (SZ - Y).T )\n",
    "    print(f\" grad done... done \")\n",
    "    return nll, grad.reshape(Theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n",
      "Loss calculating...  Z done...  nll done...  grad done... done \n"
     ]
    }
   ],
   "source": [
    "ThetaOpt = sopt.fmin_l_bfgs_b(lambda Theta: logreg_loss(Theta, vectorized_train, LR_train_target), Theta0, maxiter=500)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.89831833,  1.87011138,  0.52321257, ...,  0.96498814,\n",
       "        0.89387323,  0.9807871 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThetaOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.898318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.870111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.974915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.851720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17381</td>\n",
       "      <td>0.929919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17382</td>\n",
       "      <td>0.903717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17383</td>\n",
       "      <td>0.964988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17384</td>\n",
       "      <td>0.893873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17385</td>\n",
       "      <td>0.980787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17386 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     -3.898318\n",
       "1      1.870111\n",
       "2      0.523213\n",
       "3      0.974915\n",
       "4      0.851720\n",
       "...         ...\n",
       "17381  0.929919\n",
       "17382  0.903717\n",
       "17383  0.964988\n",
       "17384  0.893873\n",
       "17385  0.980787\n",
       "\n",
       "[17386 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta_df = pd.DataFrame(backup)\n",
    "Theta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = Theta_df.to_csv(r'LR_ThetaOpt.csv', index = True, header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>brilliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>overact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lesley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>warren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17380</td>\n",
       "      <td>hooten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17381</td>\n",
       "      <td>frewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17382</td>\n",
       "      <td>wishbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17383</td>\n",
       "      <td>ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17384</td>\n",
       "      <td>marth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17385 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      brilliant\n",
       "1        overact\n",
       "2         lesley\n",
       "3            ann\n",
       "4         warren\n",
       "...          ...\n",
       "17380     hooten\n",
       "17381     frewer\n",
       "17382    wishbon\n",
       "17383       ajax\n",
       "17384      marth\n",
       "\n",
       "[17385 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_pd = pd.DataFrame(all_train_words)\n",
    "words_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv2 = words_pd.to_csv(r'LR_all_words.csv', index = True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test = vectorize(LR_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_classify(Theta,x):\n",
    "    return (Theta.T.dot(x) >= 0)\n",
    "\n",
    "def logreg_predict(Theta,Xs):\n",
    "    return [logreg_classify(Theta,x) for x in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8216744835844726\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\"  % accuracy_score(LR_test_target, logreg_predict(ThetaOpt,vectorized_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. pure Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Data vectorization (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_clean = np.array(train_df.text)\n",
    "reviews_test_clean = np.array(test_df.text)\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((np.array([int(e) for e in train_df['rating']]) > 5) == np.array([True]*12500 + [False]*12500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x121004 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3465481 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = [1 if i < 12500 )else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 121004)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta0 = np.ones((X_train.shape[1]))\n",
    "#ThetaOpt = sopt.fmin_l_bfgs_b(lambda Theta: logreg_loss(Theta, X_train, y_train), np.array(Theta0),maxiter=100,maxfun=100,factr=1e12)[0] #liczy w nieskonczonosc albo bardzo dugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ThetaOpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2a091eea3790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %s\"\u001b[0m  \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mThetaOpt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ThetaOpt' is not defined"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy: %s\"  % accuracy_score(y_val, logreg_predict(ThetaOpt,X_val)))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
